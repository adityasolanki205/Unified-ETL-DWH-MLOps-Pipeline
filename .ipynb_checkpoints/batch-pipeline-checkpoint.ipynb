{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f958c1-1ca0-476b-ab0a-7eb7fbfcbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import argparse\n",
    "\n",
    "SCHEMA='Existing_account:STRING,Duration_month:INTEGER,Credit_history:STRING,Purpose:STRING,Credit_amount:FLOAT,Saving:STRING,Employment_duration:STRING,Installment_rate:INTEGER,Personal_status:STRING,Debtors:STRING,Residential_Duration:INTEGER,Property:STRING,Age:INTEGER,Installment_plans:STRING,Housing:STRING,Number_of_credits:INTEGER,Job:STRING,Liable_People:INTEGER,Telephone:STRING,Foreign_worker:STRING,Classification:INTEGER'\n",
    "\n",
    "\n",
    "class Split(beam.DoFn):\n",
    "    #This Function Splits the Dataset into a dictionary\n",
    "    def process(self, element):\n",
    "        Existing_account,Duration_month,Credit_history,Purpose,Credit_amount,Saving,Employment_duration,Installment_rate,Personal_status,Debtors,Residential_Duration,Property,Age,Installment_plans,Housing,Number_of_credits,Job,Liable_People,Telephone,Foreign_worker,Classification = element.split(',')\n",
    "        return [{\n",
    "            'Existing_account': str(Existing_account),\n",
    "            'Duration_month': int(Duration_month),\n",
    "            'Credit_history': str(Credit_history),\n",
    "            'Purpose': str(Purpose),\n",
    "            'Credit_amount': int(Credit_amount),\n",
    "            'Saving': str(Saving),\n",
    "            'Employment_duration':str(Employment_duration),\n",
    "            'Installment_rate': int(Installment_rate),\n",
    "            'Personal_status': str(Personal_status),\n",
    "            'Debtors': str(Debtors),\n",
    "            'Residential_Duration': int(Residential_Duration),\n",
    "            'Property': str(Property),\n",
    "            'Age': int(Age),\n",
    "            'Installment_plans':str(Installment_plans),\n",
    "            'Housing': str(Housing),\n",
    "            'Number_of_credits': int(Number_of_credits),\n",
    "            'Job': str(Job),\n",
    "            'Liable_People': int(Liable_People),\n",
    "            'Telephone': str(Telephone),\n",
    "            'Foreign_worker': str(Foreign_worker),\n",
    "            'Classification': int(Classification)\n",
    "        }]\n",
    "\n",
    "def Filter_Data(data):\n",
    "    #This will remove rows the with Null values in any one of the columns\n",
    "    return data['Purpose'] !=  'NULL' and len(data['Purpose']) <= 3  and  data['Classification'] !=  'NULL' and data['Property'] !=  'NULL' and data['Personal_status'] != 'NULL' and data['Existing_account'] != 'NULL' and data['Credit_amount'] != 'NULL' and data['Installment_plans'] != 'NULL'\n",
    "\n",
    "def Convert_Datatype(data):\n",
    "    #This will convert the datatype of columns from String to integers or Float values\n",
    "    data['Duration_month'] = int(data['Duration_month']) if 'Duration_month' in data else None\n",
    "    data['Credit_amount'] = float(data['Credit_amount']) if 'Credit_amount' in data else None\n",
    "    data['Installment_rate'] = int(data['Installment_rate']) if 'Installment_rate' in data else None\n",
    "    data['Residential_Duration'] = int(data['Residential_Duration']) if 'Residential_Duration' in data else None\n",
    "    data['Age'] = int(data['Age']) if 'Age' in data else None\n",
    "    data['Number_of_credits'] = int(data['Number_of_credits']) if 'Number_of_credits' in data else None\n",
    "    data['Liable_People'] = int(data['Liable_People']) if 'Liable_People' in data else None\n",
    "    data['Classification'] =  int(data['Classification']) if 'Classification' in data else None\n",
    "   \n",
    "    return data\n",
    "\n",
    "def Data_Wrangle(data):\n",
    "    #Here we perform data wrangling where Values in columns are converted to make more sense\n",
    "    Month_Dict = {\n",
    "    'A':'January',\n",
    "    'B':'February',\n",
    "    'C':'March',\n",
    "    'D':'April',\n",
    "    'E':'May',\n",
    "    'F':'June',\n",
    "    'G':'July',\n",
    "    'H':'August',\n",
    "    'I':'September',\n",
    "    'J':'October',\n",
    "    'K':'November',\n",
    "    'L':'December'\n",
    "    }\n",
    "    existing_account = list(data['Existing_account'])\n",
    "    for i in range(len(existing_account)):\n",
    "        month = Month_Dict[existing_account[0]]\n",
    "        days = int(''.join(existing_account[1:]))\n",
    "        data['Month'] = month\n",
    "        data['days'] = days\n",
    "    purpose = list(data['Purpose'])\n",
    "    for i in range(len(purpose)):\n",
    "        file_month = Month_Dict[purpose[0]]\n",
    "        version = int(''.join(purpose[1:]))\n",
    "        data['File_Month'] = file_month\n",
    "        data['Version'] = version\n",
    "    return data\n",
    "\n",
    "def Del_Unwanted(data):\n",
    "    #Here we delete redundant columns\n",
    "    del data['Purpose']\n",
    "    del data['Existing_account']\n",
    "    return data\n",
    "    \n",
    "def run(argv=None, save_main_session=True):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "      '--input',\n",
    "      dest='input',\n",
    "      help='Input file to process')\n",
    "    parser.add_argument(\n",
    "      '--project',\n",
    "      dest='project',\n",
    "      help='Project used for this Pipeline')\n",
    "    known_args, pipeline_args = parser.parse_known_args(argv)\n",
    "    options = PipelineOptions(pipeline_args)\n",
    "    PROJECT_ID = known_args.project\n",
    "    with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "        data = (p \n",
    "                    | 'Read Data' >> beam.io.ReadFromText(known_args.input)\n",
    "                    | 'Filter Header' >> beam.Filter(lambda line: not line.startswith(\"Existing account\"))\n",
    "                )\n",
    "        parsed_data = (data \n",
    "                     | 'Parsing Data' >> beam.ParDo(Split()))\n",
    "        filtered_data = (parsed_data\n",
    "                     | 'Filtering Data' >> beam.Filter(Filter_Data))\n",
    "        Cleaned_data = (filtered_data\n",
    "                     | 'Convert Datatypes' >> beam.Map(Convert_Datatype))\n",
    "        output =( Cleaned_data      \n",
    "                     | 'Writing to bigquery' >> beam.io.WriteToBigQuery(\n",
    "                       '{0}:GermanCredit.GermanCreditTable'.format(PROJECT_ID),\n",
    "                       schema=SCHEMA,\n",
    "                       write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "                )\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
